<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href=/assets/css/style.css>
    <link rel="shortcut icon" type="image/png" href=/assets/img/favicon.png>
    <title>Zhiqiang Zang | MIT 18.06SC Linear Algebra Session 1.1 - 1.5</title><link type="application/atom+xml" rel="alternate" href="/feed.xml" title="Zhiqiang Zang" /><!-- Begin Jekyll SEO tag v2.7.1 -->
<title>MIT 18.06SC Linear Algebra Session 1.1 - 1.5 | Zhiqiang Zang</title>
<meta name="generator" content="Jekyll v4.2.0" />
<meta property="og:title" content="MIT 18.06SC Linear Algebra Session 1.1 - 1.5" />
<meta name="author" content="zzq" />
<meta property="og:locale" content="en" />
<meta name="description" content="Hmmm‚Ä¶ I‚Äôm learning MIT 18.06SC Linear Algebra at MIT OpenCourseWare." />
<meta property="og:description" content="Hmmm‚Ä¶ I‚Äôm learning MIT 18.06SC Linear Algebra at MIT OpenCourseWare." />
<meta property="og:site_name" content="Zhiqiang Zang" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-03-10T00:00:00+00:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="MIT 18.06SC Linear Algebra Session 1.1 - 1.5" />
<script type="application/ld+json">
{"datePublished":"2018-03-10T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"/2018/03/10/MIT-Linear-Algebra-P1.html"},"dateModified":"2018-03-10T00:00:00+00:00","author":{"@type":"Person","name":"zzq"},"description":"Hmmm‚Ä¶ I‚Äôm learning MIT 18.06SC Linear Algebra at MIT OpenCourseWare.","@type":"BlogPosting","headline":"MIT 18.06SC Linear Algebra Session 1.1 - 1.5","url":"/2018/03/10/MIT-Linear-Algebra-P1.html","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
</head>
  <body><div id="banner">
  <!-- <img src="/assets/img/header.jpg" alt="header image" width="100%"> -->
  <h1>Have a nice day üòâ</h1>
</div>
<div id="menu">
  <nav>
    <ul><li>
          <a href="/">
            Home
          </a>
        </li><li>
          <a href="/blog.html">
            Blog
          </a>
        </li><li>
          <a href="/#publications">
            Publications
          </a>
        </li><li>
          <a href="/dl/zhiqiang-zang-cv.pdf">
            CV
          </a>
        </li></ul>
  </nav>
</div>
<div id="content">
      <script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       inlineMath: [ ['$','$'], ["\\(","\\)"] ],
       processEscapes: true
     }
   });
  </script>
  <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script><h1>MIT 18.06SC Linear Algebra Session 1.1 - 1.5</h1>
<p><!-- EN's date format -->
        10 Mar 2018-
    <a href="/authors/zzq.html">Zhiqiang Zang</a></p>
<hr />
<p>Hmmm‚Ä¶ I‚Äôm learning <a href="https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/index.htm">MIT 18.06SC Linear Algebra</a> at <a href="https://ocw.mit.edu/index.htm">MIT OpenCourseWare</a>.</p>

<p>OK, here we go!</p>

<h1 id="unit-i-aboldsymbolx--boldsymbolb-and-the-four-subspaces">Unit I: \(A\boldsymbol{x} = \boldsymbol{b}\) and the Four Subspaces</h1>

<h2 id="session-11-the-geometry-of-linear-equations">Session 1.1: The Geometry of Linear Equations</h2>

<p>We have a system of equations:</p>

\[\left\{
\begin{aligned}
2x - y &amp;= 0 \\
-x + 2y &amp;= 3
\end{aligned}
\right .\]

<!--more-->

<h3 id="row-picture">Row Picture</h3>

<p>Line \(2x - y = 0\) and line \(-x + 2y = 0\) intersects at the point \((1, 2)\), so \((1, 2)\) is the solution of the system of equations.</p>

<blockquote>
  <p>Maybe I should draw a X-Y coordinates here &gt;_&gt;</p>
</blockquote>

<h3 id="column-picture">Column Picture</h3>

<p>We rewrite the system of linear equations as a single equation:</p>

\[x\begin{bmatrix}2 \\ -1\end{bmatrix} + y\begin{bmatrix}-1 \\ 2\end{bmatrix} = \begin{bmatrix}0 \\ 3\end{bmatrix}\]

<p>We see \(x\) and \(y\) as scalars of column vectors: \(\boldsymbol{v_1} = \begin{bmatrix}2 \\ -1\end{bmatrix}\) and \(\boldsymbol{v_2} = \begin{bmatrix}-1 \\ 2\end{bmatrix}\), and the sum \(x\boldsymbol{v_1} + y\boldsymbol{v_2}\) is called a <em>linear combination</em> of \(\boldsymbol{v_1}\) and \(\boldsymbol{v_2}\).</p>

<p>Geometrically, we can find one copy of \(\boldsymbol{v_1}\) added to two copies of \(\boldsymbol{v_2}\) just equals the vector \(\begin{bmatrix}0 \\ 3\end{bmatrix}\). Then the solution should be \(x = 1, y =2\).</p>

<blockquote>
  <p>I will add a figure when time is available &gt;_&gt;</p>
</blockquote>

<h3 id="matrix-picture">Matrix Picture</h3>

<p>We rewrite the equations in our example as a compact form,</p>

\[A\boldsymbol{x} = \boldsymbol{b},\]

<p>that is</p>

\[\begin{bmatrix}2 &amp; -1 \\ -1 &amp; 2\end{bmatrix}\begin{bmatrix}x \\ y\end{bmatrix} = \begin{bmatrix}0 \\ 3\end{bmatrix}\]

<h3 id="matrix-multiplication">Matrix Multiplication</h3>

\[\begin{aligned}
\begin{bmatrix}2 &amp; -1 \\ -1 &amp; 2\end{bmatrix} \begin{bmatrix}1 \\ 2\end{bmatrix} = 1\begin{bmatrix}2 \\ -1\end{bmatrix} + 2\begin{bmatrix}-1 \\ 2\end{bmatrix} = \begin{bmatrix}0 \\ 3\end{bmatrix}
\end{aligned}\]

<p>A matrix times by a vector is just <strong>a linear combination of the column vectors of the matrix</strong>.</p>

<hr />

<h2 id="session-12-an-overview-of-key-ideas">Session 1.2: An Overview of Key Ideas</h2>

<h3 id="vectors">Vectors</h3>
<p>Let us take linear combinations of vectors.</p>

<h3 id="matrices">Matrices</h3>
<p>The product of a matrix and a vector is
a combination of the columns of the matrix.</p>

<h3 id="subspaces">Subspaces</h3>
<p>All combinations of column vectors creates a subspace.
The subspaces of \(\mathbb{R}^3\) are:</p>

<ul>
  <li>the origin,</li>
  <li>a line through the origin,</li>
  <li>a plane through the origin,</li>
  <li>all of \(\mathbb{R}^3\).</li>
</ul>

<h3 id="conclusion">Conclusion</h3>
<ul>
  <li>
    <p>\(A\) is invertible</p>

    <p>\(\Leftrightarrow\) \(A\boldsymbol{x} = \boldsymbol{b}\) has the unique solution \(\boldsymbol{x}\) for each \(\boldsymbol{b}\)</p>

    <p>\(\Leftrightarrow\) \(A\boldsymbol{x} = \boldsymbol{0}\) has no non-zero solution \(\boldsymbol{x}\)</p>

    <p>\(\Leftrightarrow\) The columns of \(A\) are <em>independent</em></p>

    <p>\(\Leftrightarrow\) All vectors \(A\boldsymbol{x}\) cover the whole vector space</p>

    <p>Example: \(A = \begin{bmatrix}1 &amp; 0 &amp; 0 \\ -1 &amp; 1 &amp; 0 \\ 0 &amp; -1 &amp; 1\end{bmatrix}\)</p>
  </li>
  <li>
    <p>\(A\) is not invertible</p>

    <p>\(\Leftrightarrow\) \(A\boldsymbol{x} = \boldsymbol{b}\) has a solution \(\boldsymbol{x}\) only for some of \(\boldsymbol{b}\) in the vector space</p>

    <p>\(\Leftrightarrow\) \(A\boldsymbol{x} = \boldsymbol{0}\) has non-zero solutions \(\boldsymbol{x}\)</p>

    <p>\(\Leftrightarrow\) The columns of \(A\) are <em>dependent</em></p>

    <p>\(\Leftrightarrow\) All vectors \(A\boldsymbol{x}\) lies in only a subspace of the vector space</p>

    <p>Example: \(A = \begin{bmatrix}1 &amp; 0 &amp; -1 \\ -1 &amp; 1 &amp; 0 \\ 0 &amp; -1 &amp; 1\end{bmatrix}\)</p>
  </li>
</ul>

<hr />

<h2 id="session-13-elimination-with-matrices">Session 1.3: Elimination with Matrices</h2>

<h3 id="method-of-elimination">Method of Elimination</h3>

<p>We have an example \(A\boldsymbol{x} = \boldsymbol{b}\),</p>

<p>\(A = \begin{bmatrix}1 &amp; 2 &amp; 1 \\ 3 &amp; 8 &amp; 1 \\ 0 &amp; 4 &amp; 1\end{bmatrix}\) and \(\boldsymbol{b} = \begin{bmatrix}2 \\ 12 \\2\end{bmatrix}\).</p>

<p>Steps of Elimination:</p>

<ul>
  <li>Step 1: subtract \(3\) times row \(1\) from row \(2\);</li>
  <li>Step 2: subtract \(2\) times row \(2\) from row \(3\).</li>
</ul>

\[A = \begin{bmatrix}1 &amp; 2 &amp; 1 \\ 3 &amp; 8 &amp; 1 \\ 0 &amp; 4 &amp; 1\end{bmatrix}
\rightarrow \begin{bmatrix}1 &amp; 2 &amp; 1 \\ 0 &amp; 2 &amp; -2 \\ 0 &amp; 4 &amp; 1\end{bmatrix}
\rightarrow U = \begin{bmatrix}1 &amp; 2 &amp; 1 \\ 0 &amp; 1 &amp; -2 \\ 0 &amp; 0 &amp; 5\end{bmatrix}\]

\[\boldsymbol{b} = \begin{bmatrix}2 \\ 12 \\ 2\end{bmatrix}
\rightarrow \cdots \rightarrow \begin{bmatrix}2 \\ 6 \\ -10\end{bmatrix}\]

<p>Thus, we can easily solve the systems of equations, \(\begin{bmatrix}x \\ y  \\ z\end{bmatrix} = \begin{bmatrix}2 \\ 1  \\ -2\end{bmatrix}\).</p>

<h3 id="elimination-matrices">Elimination Matrices</h3>

<p>The product of a matrix (\(3 \times 3\)) and a column vector (\(3 \times 1\)) is a column vector
(\(3 \times 1\)) that is a linear combination of the columns of the matrix.</p>

<p>The product of a row vector (\(1 \times 3\)) and a matrix (\(3 \times 3\)) is a row vector (\(1 \times 3\)) that is a linear
combination of the rows of the matrix.</p>

<p>For example,</p>

\[\begin{bmatrix}1 &amp; 0 &amp; 0 \\ -3 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1\end{bmatrix}
\begin{bmatrix}1 &amp; 2 &amp; 1 \\ 3 &amp; 8 &amp; 1 \\ 0 &amp; 4 &amp; 1\end{bmatrix}
= \begin{bmatrix}1 &amp; 2 &amp; 1 \\ 0 &amp; 2 &amp; -2 \\ 0 &amp; 4 &amp; 1\end{bmatrix}.\]

<p>Multiplying on the left by a permutation matrix exchanges the rows of a matrix, while multiplying on the right exchanges the columns. For example,</p>

\[P = \begin{bmatrix}0 &amp; 1 &amp; 0 \\ 1 &amp; 0 &amp; 0 \\ 0 &amp; 0 &amp; 1\end{bmatrix}.\]

<p>\(P\) is a <em>permutation matrix</em> and the first and second rows of the matrix \(PA\) are the second and first rows of the matrix \(A\).</p>

<p>Note, matrix multiplication is <em>associative</em> but <em>not commutative</em>.</p>

<h3 id="inverses">Inverses</h3>
<p>We have a matrix:</p>

\[E_{21} = \begin{bmatrix}1 &amp; 0 &amp; 0 \\ -3 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1\end{bmatrix}\]

<p>which subtracts \(3\) times row \(1\) from row \(2\). To ‚Äú<strong>undo</strong>‚Äù this operation we must add \(3\) times row \(1\) to row \(2\) using the inverse matrix:</p>

\[E_{21}^{-1} = \begin{bmatrix}1 &amp; 0 &amp; 0 \\ 3 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1\end{bmatrix}.\]

<p>In fact, \(E_{21}^{-1}E_{21} = I\).</p>

<hr />

<h2 id="session-14-multiplication-and-inverse-matrices">Session 1.4: Multiplication and Inverse Matrices</h2>

<h3 id="four-and-a-half-ways-we-see-matrix-multiplication">Four and a half ways we see matrix multiplication</h3>

<p>We have \(AB = C\). \(A\) is an \(m \times n\) matrix and \(B\) is an \(n \times p\) matrix, then \(C\) is an \(m \times p\) matrix. We use \(c_{ij}\) to denote the entry in row \(i\) and column \(j\) of matrix \(C\) and the same denotation applies to \(a_{ij}\) and \(b_{ij}\).</p>

<h4 id="row-times-column">Row times column</h4>

\[c_{ij} = \sum_{k=1}^n a_{ik}b_{kj}\]

<h4 id="columns">Columns</h4>

<p>The product of matrix \(A\) and column \(j\) of matrix \(B\) equals column \(j\) of matrix \(C\). This tells us that the columns of \(C\) are combinations of columns of \(A\).</p>

\[A
\begin{bmatrix}
| &amp; | &amp; | \\
column 1 &amp; column 2 &amp; column 3 \\
| &amp; | &amp; |
\end{bmatrix}
=\begin{bmatrix}
| &amp; | &amp; | \\
A(column 1) &amp; A(column 2) &amp; A(column 3) \\
| &amp; | &amp; |
\end{bmatrix}\]

<h4 id="rows">Rows</h4>
<p>The product of row \(i\) of matrix \(A\) and matrix \(B\) equals row \(i\) of matrix \(C\). So the rows of \(C\) are combinations of rows of \(B\).</p>

\[\left[
\begin{matrix}
--- &amp; row 1 &amp; --- \\
--- &amp; row 2 &amp; --- \\
--- &amp; row 3 &amp; ---
\end{matrix}
\right]
B
=\left[
\begin{matrix}
--- &amp; (row 1)B &amp; --- \\
--- &amp; (row 2)B &amp; --- \\
--- &amp; (row 3)B &amp; ---
\end{matrix}
\right]\]

<h4 id="column-times-row">Column times row</h4>

\[AB = \sum_{k=1}{n}
\begin{bmatrix}a_{1k} \\ \vdots \\ a_{mk}\end{bmatrix}
\begin{bmatrix}b_{k1} &amp; \cdots &amp; b_{kp}\end{bmatrix}\]

<blockquote>
  <p>note: Here I fixed a typo in the <a href="https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/ax-b-and-the-four-subspaces/multiplication-and-inverse-matrices/MIT18_06SCF11_Ses1.3sum.pdf">lecture summary (PDf)</a> of this session: \(b_{kp}\) instead of the original \(b_{kn}\).</p>
</blockquote>

<h4 id="blocks">Blocks</h4>

\[\begin{bmatrix}A_1 &amp; A_2 \\ A_3 &amp; A_4 \end{bmatrix}
\begin{bmatrix}B_1 &amp; B_2 \\ B_3 &amp; B_4 \end{bmatrix}
=\begin{bmatrix}
A_1B_1+A_2B_3 &amp; A_1B_2+A_2B_4 \\
A_3B_1+A_4B_3 &amp; A_3B_2+A_4B_4
\end{bmatrix}\]

<h3 id="inverses-1">Inverses</h3>

<p>If \(A\) is <em>singular</em> or <em>not invertible</em>,</p>

<p>then A does not have an inverse,</p>

<p>and we can find some non-zero vector \(\boldsymbol{x}\) for which \(A\boldsymbol{x} = \boldsymbol{0}\)</p>

<h4 id="gauss-jordan-elimination">Gauss-Jordan Elimination</h4>

<p>\(E
\left[
\begin{array}{c|c}
A &amp; I
\end{array}
\right]
=\left[
\begin{array}{c|c}
I &amp; E
\end{array}
\right]\)
If \(EA = I\), then \(E = A^{-1}\).</p>

<hr />

<h2 id="session-15-factorization-into-a--lu">Session 1.5: Factorization into \(A = LU\)</h2>

<h3 id="inverse-of-a-product">Inverse of a product</h3>

\[(AB)^{-1} = B^{-1}A^{-1}\]

<h3 id="transpose-of-a-product">Transpose of a product</h3>

\[(AB)^{T} = B^{T}A^{T}, \quad (A^{T})^{-1} = (A^{-1})^{T}\]

<h3 id="a--lu">\(A = LU\)</h3>

<p>We can use elimination to convert \(A\) into an upper triangular matrix \(U\), that is \(EA = U\), and further we can also convert this to a factorization \(A = LU\) in which \(L = E^{-1}\).</p>

<p>For example, in a three dimensional case, if \(E_{32}E_{31}E_{21}A = U\) then \(A=E_{21}^{-1}E_{31}^{-1}E_{32}^{-1}U = LU\). Suppose \(E_{31}\) is the identity matrix and \(E_{32}\) and \(E_{21}\) are as shown below:</p>

\[\begin{array}{cccc}
E_{32} &amp; E_{21} &amp; &amp; E \\
\begin{bmatrix}1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; -5 &amp; 1\end{bmatrix}
&amp; \begin{bmatrix}1 &amp; 0 &amp; 0 \\ -2 &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1\end{bmatrix}
&amp; = &amp; \begin{bmatrix}1 &amp; 0 &amp; 0 \\ -2 &amp; 1 &amp; 0 \\ 10 &amp; -5 &amp; 1\end{bmatrix}
\end{array}.\]

<p>Here \(L = E^{-1} = E_{21}^{-1}E_{32}^{-1}\):</p>

\[\begin{array}{cccc}
E_{21}^{-1} &amp; E_{32}^{-1} &amp; &amp; L \\
\begin{bmatrix}1 &amp; 0 &amp; 0 \\ \underline{2} &amp; 1 &amp; 0 \\ 0 &amp; 0 &amp; 1\end{bmatrix}
&amp; \begin{bmatrix}1 &amp; 0 &amp; 0 \\ 0 &amp; 1 &amp; 0 \\ 0 &amp; \underline{5} &amp; 1\end{bmatrix}
&amp; = &amp; \begin{bmatrix}1 &amp; 0 &amp; 0 \\ \underline{2} &amp; 1 &amp; 0 \\ 0 &amp; \underline{5} &amp; 1\end{bmatrix}
\end{array}\]

<p>Notice the \(0\) in row three column one of \(L\), where \(E\) had a \(10\). The factorization \(A = LU\) is preferable to the statement \(EA = U\) because the combination of row subtractions does not have the effect on \(L\) that it did on \(E\).</p>

<p><strong>If there are no row exchanges, the multipliers from the elimination matrices are copied directly into \(L\).</strong></p>

<h3 id="cost-of-elimination">Cost of elimination</h3>

<p>If we define a typical operation is to multiply one row and then subtract it from another, then the total number of operations needed to factor \(n \times n\) \(A\) into \(LU\) is on the order of \(n^3\):</p>

\[1^2 + 2^2 + \cdots + (n - 1)^2 + n^2 = \sum_{i = 1}^{n}i^2 \approx \int_0^n x\,\mathrm{d}x = \frac{1}{3}n^3.\]

<p>While we‚Äôre factoring \(A\) we‚Äôre also operating on \(\boldsymbol{b}\). That costs about \(n^2\) operations, which is hardly worth counting compared to \(1/3n^3\).</p>

<h3 id="row-exchanges">Row exchanges</h3>

<p>The inverse of any permutation matrix \(P\) is \(P^{-1} = P^{T}\).</p>

<p>There are \(n!\) different ways to permute the rows of an \(n \times n\) matrix (including the permutation that leaves all rows unfixed) so there are \(n!\) permutation matrices. These matrices form a <em>multiplicative group</em>.</p>

<hr />

<p>This work is built upon the materials on <a href="https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/index.htm">MIT OCW</a>.</p>

<hr /><p><strong>LICENSE</strong>:</p>
  <p><a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>
    </div>
    <div id="clear"></div><div id="footer">
  <div id="inner">
    ¬© 2021 Zhiqiang Zang<br/>
    Favicon made by <a href="http://www.freepik.com/" target="_blank">Freepik</a> from <a href="http://www.flaticon.com/" target="_blank">www.flaticon.com</a> licensed by <a href="http://creativecommons.org/licenses/by/3.0/" target="_blank">CC 3.0 BY</a>
  </div>
</div>
</body>
</html>
