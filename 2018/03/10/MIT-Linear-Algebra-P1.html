<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" href=/assets/css/style.css>
    <link rel="shortcut icon" type="image/png" href=/assets/img/favicon.png>
    <title>Zhiqiang Zang | MIT 18.06SC Linear Algebra Session 1.1 - 1.5</title>
    <link type="application/atom+xml" rel="alternate" href="/feed.xml" title="Zhiqiang Zang" />
    <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>MIT 18.06SC Linear Algebra Session 1.1 - 1.5 | Zhiqiang Zang</title>
<meta name="generator" content="Jekyll v4.0.0" />
<meta property="og:title" content="MIT 18.06SC Linear Algebra Session 1.1 - 1.5" />
<meta name="author" content="zzq" />
<meta property="og:locale" content="en" />
<meta name="description" content="Hmmm‚Ä¶ I‚Äôm learning MIT 18.06SC Linear Algebra at MIT OpenCourseWare." />
<meta property="og:description" content="Hmmm‚Ä¶ I‚Äôm learning MIT 18.06SC Linear Algebra at MIT OpenCourseWare." />
<meta property="og:site_name" content="Zhiqiang Zang" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-03-10T00:00:00+00:00" />
<script type="application/ld+json">
{"description":"Hmmm‚Ä¶ I‚Äôm learning MIT 18.06SC Linear Algebra at MIT OpenCourseWare.","headline":"MIT 18.06SC Linear Algebra Session 1.1 - 1.5","dateModified":"2018-03-10T00:00:00+00:00","datePublished":"2018-03-10T00:00:00+00:00","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"/2018/03/10/MIT-Linear-Algebra-P1.html"},"url":"/2018/03/10/MIT-Linear-Algebra-P1.html","author":{"@type":"Person","name":"zzq"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  </head>
  <body>
    <div id="banner">
  <!-- <img src="/assets/img/header.jpg" alt="header image" width="100%"> -->
  <h1>Have a nice day üòâ</h1>
</div>

    <div id="menu">
  <nav>
    <ul>
      
        <li>
          <a href="/" >
            Home
          </a>
        </li>
      
        <li>
          <a href="/blog.html" >
            Blog
          </a>
        </li>
      
        <li>
          <a href="/misc.html" >
            Misc
          </a>
        </li>
      
        <li>
          <a href="/resume.html" >
            Resume
          </a>
        </li>
      
        <li>
          <a href="/contact.html" >
            Contact
          </a>
        </li>
      
    </ul>
  </nav>
</div>

    <div id="content">
      
  <script type="text/x-mathjax-config">
   MathJax.Hub.Config({
     tex2jax: {
       inlineMath: [ ['$','$'], ["\\(","\\)"] ],
       processEscapes: true
     }
   });
  </script>
  <script type="text/javascript" async
      src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>


<h1>MIT 18.06SC Linear Algebra Session 1.1 - 1.5</h1>
<p>
  
    
        <!-- EN's date format -->
        10 Mar 2018
      
  
  
  
    -
    <a href="/authors/zzq.html">
    
        Zhiqiang Zang
      
    </a>
  
</p>
<hr />
<p>Hmmm‚Ä¶ I‚Äôm learning <a href="https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/index.htm">MIT 18.06SC Linear Algebra</a> at <a href="https://ocw.mit.edu/index.htm">MIT OpenCourseWare</a>.</p>

<p>OK, here we go!</p>

<h1 id="unit-i-aboldsymbolx--boldsymbolb-and-the-four-subspaces">Unit I: $A\boldsymbol{x} = \boldsymbol{b}$ and the Four Subspaces</h1>

<h2 id="session-11-the-geometry-of-linear-equations">Session 1.1: The Geometry of Linear Equations</h2>

<p>We have a system of equations:
<script type="math/tex">% <![CDATA[
\left\{
\begin{aligned}
2x - y &= 0 \\
-x + 2y &= 3
\end{aligned}
\right . %]]></script></p>

<!--more-->

<h3 id="row-picture">Row Picture</h3>

<p>Line $2x - y = 0$ and line $-x + 2y = 0$ intersects at the point $(1, 2)$, so $(1, 2)$ is the solution of the system of equations.</p>

<blockquote>
  <p>Maybe I should draw a X-Y coordinates here &gt;_&gt;</p>
</blockquote>

<h3 id="column-picture">Column Picture</h3>

<p>We rewrite the system of linear equations as a single equation:</p>

<script type="math/tex; mode=display">x\begin{bmatrix}2 \\ -1\end{bmatrix} + y\begin{bmatrix}-1 \\ 2\end{bmatrix} = \begin{bmatrix}0 \\ 3\end{bmatrix}</script>

<p>We see $x$ and $y$ as scalars of column vectors: $\boldsymbol{v_1} = \begin{bmatrix}2 \ -1\end{bmatrix}$ and $\boldsymbol{v_2} = \begin{bmatrix}-1 \ 2\end{bmatrix}$, and the sum $x\boldsymbol{v_1} + y\boldsymbol{v_2}$ is called a <em>linear combination</em> of $\boldsymbol{v_1}$ and $\boldsymbol{v_2}$.</p>

<p>Geometrically, we can find one copy of $\boldsymbol{v_1}$ added to two copies of $\boldsymbol{v_2}$ just equals the vector $\begin{bmatrix}0 \ 3\end{bmatrix}$. Then the solution should be $x = 1, y =2$.</p>

<blockquote>
  <p>I will add a figure when time is available &gt;_&gt;</p>
</blockquote>

<h3 id="matrix-picture">Matrix Picture</h3>

<p>We rewrite the equations in our example as a compact form,</p>

<script type="math/tex; mode=display">A\boldsymbol{x} = \boldsymbol{b},</script>

<p>that is</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{bmatrix}2 & -1 \\ -1 & 2\end{bmatrix}\begin{bmatrix}x \\ y\end{bmatrix} = \begin{bmatrix}0 \\ 3\end{bmatrix} %]]></script>

<h3 id="matrix-multiplication">Matrix Multiplication</h3>

<script type="math/tex; mode=display">% <![CDATA[
\begin{aligned}
\begin{bmatrix}2 & -1 \\ -1 & 2\end{bmatrix} \begin{bmatrix}1 \\ 2\end{bmatrix} = 1\begin{bmatrix}2 \\ -1\end{bmatrix} + 2\begin{bmatrix}-1 \\ 2\end{bmatrix} = \begin{bmatrix}0 \\ 3\end{bmatrix}
\end{aligned} %]]></script>

<p>A matrix times by a vector is just <strong>a linear combination of the column vectors of the matrix</strong>.</p>

<hr />

<h2 id="session-12-an-overview-of-key-ideas">Session 1.2: An Overview of Key Ideas</h2>

<h3 id="vectors">Vectors</h3>
<p>Let us take linear combinations of vectors.</p>

<h3 id="matrices">Matrices</h3>
<p>The product of a matrix and a vector is
a combination of the columns of the matrix.</p>

<h3 id="subspaces">Subspaces</h3>
<p>All combinations of column vectors creates a subspace.
The subspaces of $\mathbb{R}^3$ are:</p>

<ul>
  <li>the origin,</li>
  <li>a line through the origin,</li>
  <li>a plane through the origin,</li>
  <li>all of $\mathbb{R}^3$.</li>
</ul>

<h3 id="conclusion">Conclusion</h3>
<ul>
  <li>
    <p>$A$ is invertible</p>

    <p>$\Leftrightarrow$ $A\boldsymbol{x} = \boldsymbol{b}$ has the unique solution $\boldsymbol{x}$ for each $\boldsymbol{b}$</p>

    <p>$\Leftrightarrow$ $A\boldsymbol{x} = \boldsymbol{0}$ has no non-zero solution $\boldsymbol{x}$</p>

    <p>$\Leftrightarrow$ The columns of $A$ are <em>independent</em></p>

    <p>$\Leftrightarrow$ All vectors $A\boldsymbol{x}$ cover the whole vector space</p>

    <p>Example: $A = \begin{bmatrix}1 &amp; 0 &amp; 0 \ -1 &amp; 1 &amp; 0 \ 0 &amp; -1 &amp; 1\end{bmatrix}$</p>
  </li>
  <li>
    <p>$A$ is not invertible</p>

    <p>$\Leftrightarrow$ $A\boldsymbol{x} = \boldsymbol{b}$ has a solution $\boldsymbol{x}$ only for some of $\boldsymbol{b}$ in the vector space</p>

    <p>$\Leftrightarrow$ $A\boldsymbol{x} = \boldsymbol{0}$ has non-zero solutions $\boldsymbol{x}$</p>

    <p>$\Leftrightarrow$ The columns of $A$ are <em>dependent</em></p>

    <p>$\Leftrightarrow$ All vectors $A\boldsymbol{x}$ lies in only a subspace of the vector space</p>

    <p>Example: $A = \begin{bmatrix}1 &amp; 0 &amp; -1 \ -1 &amp; 1 &amp; 0 \ 0 &amp; -1 &amp; 1\end{bmatrix}$</p>
  </li>
</ul>

<hr />

<h2 id="session-13-elimination-with-matrices">Session 1.3: Elimination with Matrices</h2>

<h3 id="method-of-elimination">Method of Elimination</h3>

<p>We have an example $A\boldsymbol{x} = \boldsymbol{b}$,</p>

<p>$A = \begin{bmatrix}1 &amp; 2 &amp; 1 \ 3 &amp; 8 &amp; 1 \ 0 &amp; 4 &amp; 1\end{bmatrix}$ and $\boldsymbol{b} = \begin{bmatrix}2 \ 12 \2\end{bmatrix}$.</p>

<p>Steps of Elimination:</p>

<ul>
  <li>Step 1: subtract $3$ times row 1 from row 2;</li>
  <li>Step 2: subtract $2$ times row 2 from row 3.</li>
</ul>

<script type="math/tex; mode=display">% <![CDATA[
A = \begin{bmatrix}1 & 2 & 1 \\ 3 & 8 & 1 \\ 0 & 4 & 1\end{bmatrix}
\rightarrow \begin{bmatrix}1 & 2 & 1 \\ 0 & 2 & -2 \\ 0 & 4 & 1\end{bmatrix}
\rightarrow U = \begin{bmatrix}1 & 2 & 1 \\ 0 & 1 & -2 \\ 0 & 0 & 5\end{bmatrix} %]]></script>

<script type="math/tex; mode=display">\boldsymbol{b} = \begin{bmatrix}2 \\ 12 \\ 2\end{bmatrix}
\rightarrow \cdots \rightarrow \begin{bmatrix}2 \\ 6 \\ -10\end{bmatrix}</script>

<p>Thus, we can easily solve the systems of equations, $\begin{bmatrix}x \ y  \ z\end{bmatrix} = \begin{bmatrix}2 \ 1  \ -2\end{bmatrix}$.</p>

<h3 id="elimination-matrices">Elimination Matrices</h3>

<p>The product of a matrix (3x3) and a column vector (3x1) is a column vector
(3x1) that is a linear combination of the columns of the matrix.</p>

<p>The product of a row vector (1x3) and a matrix (3x3) is a row vector (1x3) that is a linear
combination of the rows of the matrix.</p>

<p>For example,</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{bmatrix}1 & 0 & 0 \\ -3 & 1 & 0 \\ 0 & 0 & 1\end{bmatrix}
\begin{bmatrix}1 & 2 & 1 \\ 3 & 8 & 1 \\ 0 & 4 & 1\end{bmatrix}
= \begin{bmatrix}1 & 2 & 1 \\ 0 & 2 & -2 \\ 0 & 4 & 1\end{bmatrix}. %]]></script>

<p>Multiplying on the left by a permutation matrix exchanges the rows of a matrix, while multiplying on the right exchanges the columns. For example,</p>

<script type="math/tex; mode=display">% <![CDATA[
P = \begin{bmatrix}0 & 1 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 1\end{bmatrix}. %]]></script>

<p>$P$ is a <em>permutation matrix</em> and the first and second rows of the matrix $PA$ are the second and first rows of the matrix $A$.</p>

<p>Note, matrix multiplication is <em>associative</em> but <em>not commutative</em>.</p>

<h3 id="inverses">Inverses</h3>
<p>We have a matrix:</p>

<script type="math/tex; mode=display">% <![CDATA[
E_{21} = \begin{bmatrix}1 & 0 & 0 \\ -3 & 1 & 0 \\ 0 & 0 & 1\end{bmatrix} %]]></script>

<p>which subtracts $3$ times row 1 from row 2. To ‚Äú<strong>undo</strong>‚Äù this operation we must add $3$ times row 1 to row 2 using the inverse matrix:</p>

<script type="math/tex; mode=display">% <![CDATA[
E_{21}^{-1} = \begin{bmatrix}1 & 0 & 0 \\ 3 & 1 & 0 \\ 0 & 0 & 1\end{bmatrix}. %]]></script>

<p>In fact, $E_{21}^{-1}E_{21} = I$.</p>

<hr />

<h2 id="session-14-multiplication-and-inverse-matrices">Session 1.4: Multiplication and Inverse Matrices</h2>

<h3 id="four-and-a-half-ways-we-see-matrix-multiplication">Four and a half ways we see matrix multiplication</h3>

<p>We have $AB = C$. $A$ is an $m \times n$ matrix and $B$ is an $n \times p$ matrix, then $C$ is an $m \times p$ matrix. We use $c_{ij}$ to denote the entry in row $i$ and column $j$ of matrix $C$ and the same denotation applies to $a_{ij}$ and $b_{ij}$.</p>

<h4 id="row-times-column">Row times column</h4>

<p>$c_{ij} = \sum_{k=1}^n a_{ik}b_{kj}$</p>

<h4 id="columns">Columns</h4>

<p>The product of matrix $A$ and column $j$ of matrix $B$ equals column $j$ of matrix $C$. This tells us that the columns of $C$ are combinations of columns of $A$.</p>

<script type="math/tex; mode=display">% <![CDATA[
A
\begin{bmatrix}
| & | & | \\
column 1 & column 2 & column 3 \\
| & | & |
\end{bmatrix}
=\begin{bmatrix}
| & | & | \\
A(column 1) & A(column 2) & A(column 3) \\
| & | & |
\end{bmatrix} %]]></script>

<h4 id="rows">Rows</h4>
<p>The product of row $i$ of matrix $A$ and matrix $B$ equals row $i$ of matrix $C$. So the rows of $C$ are combinations of rows of $B$.</p>

<script type="math/tex; mode=display">% <![CDATA[
\left[
\begin{matrix}
--- & row 1 & --- \\
--- & row 2 & --- \\
--- & row 3 & ---
\end{matrix}
\right]
B
=\left[
\begin{matrix}
--- & (row 1)B & --- \\
--- & (row 2)B & --- \\
--- & (row 3)B & ---
\end{matrix}
\right] %]]></script>

<h4 id="column-times-row">Column times row</h4>

<script type="math/tex; mode=display">% <![CDATA[
AB = \sum_{k=1}{n}
\begin{bmatrix}a_{1k} \\ \vdots \\ a_{mk}\end{bmatrix}
\begin{bmatrix}b_{k1} & \cdots & b_{kp}\end{bmatrix} %]]></script>

<blockquote>
  <p>note: Here I fixed a typo in the <a href="https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/ax-b-and-the-four-subspaces/multiplication-and-inverse-matrices/MIT18_06SCF11_Ses1.3sum.pdf">lecture summary (PDf)</a> of this session: $b_{kp}$ instead of the original $b_{kn}$.</p>
</blockquote>

<h4 id="blocks">Blocks</h4>

<script type="math/tex; mode=display">% <![CDATA[
\begin{bmatrix}A_1 & A_2 \\ A_3 & A_4 \end{bmatrix}
\begin{bmatrix}B_1 & B_2 \\ B_3 & B_4 \end{bmatrix}
=\begin{bmatrix}
A_1B_1+A_2B_3 & A_1B_2+A_2B_4 \\
A_3B_1+A_4B_3 & A_3B_2+A_4B_4
\end{bmatrix} %]]></script>

<h3 id="inverses-1">Inverses</h3>

<p>If $A$ is <em>singular</em> or <em>not invertible</em>,</p>

<p>then A does not have an inverse,</p>

<p>and we can find some non-zero vector $\boldsymbol{x}$ for which $A\boldsymbol{x} = \boldsymbol{0}$</p>

<h4 id="gauss-jordan-elimination">Gauss-Jordan Elimination</h4>

<p><script type="math/tex">% <![CDATA[
E
\left[
\begin{array}{c|c}
A & I
\end{array}
\right]
=\left[
\begin{array}{c|c}
I & E
\end{array}
\right] %]]></script>
If $EA = I$, then $E = A^{-1}$.</p>

<hr />

<h2 id="session-15-factorization-into-a--lu">Session 1.5: Factorization into $A = LU$</h2>

<h3 id="inverse-of-a-product">Inverse of a product</h3>

<script type="math/tex; mode=display">(AB)^{-1} = B^{-1}A^{-1}</script>

<h3 id="transpose-of-a-product">Transpose of a product</h3>

<script type="math/tex; mode=display">(AB)^{T} = B^{T}A^{T}, \quad (A^{T})^{-1} = (A^{-1})^{T}</script>

<h3 id="a--lu">$A = LU$</h3>

<p>We can use elimination to convert $A$ into an upper triangular matrix $U$, that is $EA = U$, and further we can also convert this to a factorization $A = LU$ in which $L = E^{-1}$.</p>

<p>For example, in a three dimensional case, if $E_{32}E_{31}E_{21}A = U$ then $A=E_{21}^{-1}E_{31}^{-1}E_{32}^{-1}U = LU$. Suppose $E_{31}$ is the identity matrix and $E_{32}$ and $E_{21}$ are as shown below:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{array}{cccc}
E_{32} & E_{21} & & E \\
\begin{bmatrix}1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & -5 & 1\end{bmatrix}
& \begin{bmatrix}1 & 0 & 0 \\ -2 & 1 & 0 \\ 0 & 0 & 1\end{bmatrix}
& = & \begin{bmatrix}1 & 0 & 0 \\ -2 & 1 & 0 \\ 10 & -5 & 1\end{bmatrix}
\end{array}. %]]></script>

<p>Here $L = E^{-1} = E_{21}^{-1}E_{32}^{-1}$:</p>

<script type="math/tex; mode=display">% <![CDATA[
\begin{array}{cccc}
E_{21}^{-1} & E_{32}^{-1} & & L \\
\begin{bmatrix}1 & 0 & 0 \\ \underline{2} & 1 & 0 \\ 0 & 0 & 1\end{bmatrix}
& \begin{bmatrix}1 & 0 & 0 \\ 0 & 1 & 0 \\ 0 & \underline{5} & 1\end{bmatrix}
& = & \begin{bmatrix}1 & 0 & 0 \\ \underline{2} & 1 & 0 \\ 0 & \underline{5} & 1\end{bmatrix}
\end{array} %]]></script>

<p>Notice the 0 in row three column one of $L$, where $E$ had a $10$. The factorization $A = LU$ is preferable to the statement $EA = U$ because the combination of row subtractions does not have the effect on $L$ that it did on $E$.</p>

<p><strong>If there are no row exchanges, the multipliers from the elimination matrices are copied directly into $L$.</strong></p>

<h3 id="cost-of-elimination">Cost of elimination</h3>

<p>If we define a typical operation is to multiply one row and then subtract it from another, then the total number of operations needed to factor $n \times n$ $A$ into $LU$ is on the order of $n^3$:</p>

<script type="math/tex; mode=display">1^2 + 2^2 + \cdots + (n - 1)^2 + n^2 = \sum_{i = 1}^{n}i^2 \approx \int_0^n x\,\mathrm{d}x = \frac{1}{3}n^3.</script>

<p>While we‚Äôre factoring $A$ we‚Äôre also operating on $\boldsymbol{b}$. That costs about $n^2$ operations, which is hardly worth counting compared to $1/3n^3$.</p>

<h3 id="row-exchanges">Row exchanges</h3>

<p>The inverse of any permutation matrix $P$ is $P^{-1} = P^{T}$.</p>

<p>There are $n!$ different ways to permute the rows of an $n \times n$ matrix (including the permutation that leaves all rows unfixed) so there are $n!$ permutation matrices. These matrices form a <em>multiplicative group</em>.</p>

<hr />

<p>This work is built upon the materials on <a href="https://ocw.mit.edu/courses/mathematics/18-06sc-linear-algebra-fall-2011/index.htm">MIT OCW</a>.</p>

<hr />

  <p><strong>LICENSE</strong>:</p>
  <p><a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/"><img alt="Creative Commons License" style="border-width:0" src="https://i.creativecommons.org/l/by-nc-sa/4.0/88x31.png" /></a><br />This work is licensed under a <a rel="license" href="http://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License</a>.</p>
  


    </div>
    <div id="clear"></div>
    <div id="footer">
  2019@Zhiqiang Zang
</div>

  </body>
</html>
